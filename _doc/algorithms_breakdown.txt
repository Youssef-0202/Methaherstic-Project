# ALGORITHM BREAKDOWN: HOW THEY WORK

## 1. TABU SEARCH (TS)
*   **Representation:** Direct (e.g., Array where Index=Time, Value=Class).
*   **Move:** Best Neighbor. It evaluates *all* (or many) neighbors and picks the absolute best one, even if it's worse than the current solution.
*   **Intensification:**
    *   **Greedy Descent:** It aggressively pursues the best local path.
    *   **Aspiration Criteria:** If a move is "Tabu" but finds a new global best score, the rule is ignored to grab that solution.
*   **Diversification:**
    *   **Tabu List:** A short-term memory that forbids reversing recent moves (e.g., "Don't move Class A back to Monday for 10 turns"). This forces the algorithm to explore new directions.
    *   **Frequency Memory:** Penalizes moves that have been made too often in the long run.
*   **Candidate:** A neighbor in the immediate neighborhood (e.g., one swap away). TS generates *many* candidates at once.
*   **Good Solution:** One with the lowest cost found so far that isn't Tabu (or meets aspiration criteria).

## 2. SIMULATED ANNEALING (SA)
*   **Representation:** Direct.
*   **Move:** Random. It picks *one* random neighbor (e.g., Swap two classes).
*   **Intensification:**
    *   **Low Temperature:** As the "temperature" cools down, the probability of accepting worse moves drops to near zero. The algorithm effectively becomes a greedy hill-climber, refining the local area.
*   **Diversification:**
    *   **High Temperature:** At the start (or during re-heating), the algorithm accepts *worse* solutions with high probability. This allows it to climb out of local optima valleys and jump to different parts of the search space.
*   **Candidate:** A single random neighbor generated by a move.
*   **Good Solution:** A candidate that has a lower cost (Delta E < 0) OR a higher cost that is accepted by the Metropolis probability ($e^{-\Delta E/T}$).

## 3. ANT COLONY OPTIMIZATION (ACO)
*   **Representation:** Construction Graph. A solution is a "path" taken by an ant through a graph of possibilities.
*   **Move:** Probabilistic Step. An ant builds a solution step-by-step (e.g., assigning one class at a time) based on Pheromone levels and Heuristic info.
*   **Intensification:**
    *   **Pheromone Deposit:** Successful ants leave pheromones on their path. Future ants are attracted to these "strong" paths, focusing the search on good solutions.
*   **Diversification:**
    *   **Evaporation:** Pheromones disappear over time. This prevents the colony from getting stuck on one path too early.
    *   **Probabilistic Choice:** Ants don't always follow the strongest trail; there is always a random chance to explore a new, unvisited path.
*   **Candidate:** A partial path being built by an ant (step-by-step) or the fully constructed path once finished.
*   **Good Solution:** A complete path that has a high pheromone concentration (meaning many ants found it successful) and low cost.

## 4. GENETIC ALGORITHM (GA)
*   **Representation:** Chromosome. The schedule is encoded as a string or array of "genes" (assignments).
*   **Move:**
    *   **Crossover:** Combining two parent solutions to create a child.
    *   **Mutation:** Randomly changing a gene (e.g., moving one class).
*   **Intensification:**
    *   **Selection:** "Survival of the Fittest." Only the best solutions are chosen to be parents, concentrating the search in high-quality areas.
    *   **Crossover:** Combines the "good traits" of two parents to hopefully create a better child.
*   **Diversification:**
    *   **Mutation:** Randomly flipping bits or swapping genes prevents the population from becoming identical (premature convergence).
*   **Candidate:** An individual "Child" created by crossover/mutation, waiting to see if it's fit enough to enter the next generation.
*   **Good Solution:** An individual with high "Fitness" (low cost) that survives selection.

## 5. PARTICLE SWARM OPTIMIZATION (PSO)
*   **Representation:** Position Vector. Each particle represents a complete schedule as a set of coordinates in a multi-dimensional space.
*   **Move:** Velocity Update. A particle moves by adding a "velocity" vector to its current position. This velocity is influenced by:
    1.  **Inertia:** Its previous direction.
    2.  **Cognitive Component:** Attraction to its own personal best position ($pbest$).
    3.  **Social Component:** Attraction to the swarm's global best position ($gbest$).
*   **Intensification:**
    *   **Attraction to Best:** The pull towards $gbest$ and $pbest$ forces particles to converge around the most promising areas found so far.
*   **Diversification:**
    *   **Inertia & Randomness:** The inertia weight ($w$) keeps particles moving (preventing instant stagnation), and random coefficients ($r_1, r_2$) add stochastic noise to the trajectory.
*   **Candidate:** A "Particle" at a new position.
*   **Good Solution:** The Global Best ($gbest$) position found by the entire swarm.

## 6. FIRE HAWK OPTIMIZER (FHO)
*   **Representation:** Hawk Position. Each hawk is a candidate solution vector.
*   **Move:** Based on nature's "Fire Hawks" (birds that spread fire to flush out prey).
    *   **Attraction:** Hawks move towards the best solution (the "Fire").
    *   **Repulsion:** They avoid getting too close to others to prevent crowding.
    *   **Mutation:** Random changes to explore new areas.
*   **Intensification:**
    *   **Attraction to Fire:** The strong pull towards the best-known solution drives the population to exploit that area.
*   **Diversification:**
    *   **Repulsion & Mutation:** The repulsion mechanism ensures hawks stay spread out (covering more ground), and mutation allows for random jumps to completely new areas.
*   **Candidate:** A "Fire Hawk" (agent) in the population.
*   **Good Solution:** The position of the primary Fire Hawk (the leader/best agent).

## 7. WATERWHEEL PLANT ALGORITHM (WWPA)
*   **Representation:** Plant Position. Each agent acts as a waterwheel plant searching for prey.
*   **Move:** Mimics the hunting behavior.
    *   **Hunting (Exploration):** Large shifts in position to find prey in new waters.
    *   **Processing (Exploitation):** Small, refined adjustments to capture/digest prey in a known good spot.
*   **Intensification:**
    *   **Processing Phase:** Once prey is found (a good area), the algorithm uses small steps to fine-tune the solution locally.
*   **Diversification:**
    *   **Hunting Phase:** The algorithm forces agents to make large moves to unexplored regions.
    *   **Mutation:** If a plant doesn't catch prey (improve) for a set time, it mutates (jumps) to a new location to avoid starvation (stagnation).
*   **Candidate:** A "Plant" agent.
*   **Good Solution:** The plant that has captured the most "prey" (highest fitness score).
